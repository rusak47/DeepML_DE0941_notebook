{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cac5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen: 200; device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.99M/2.99M [00:01<00:00, 2.45MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "epoch: 1 loss_train: 0.0692186787724495 loss_test: 0.11517823114991188 acc_plot_train: 0.0 acc_plot_test: 0.0 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+4AAAZGCAYAAAAxk/uaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWCBJREFUeJzs3X2c1nWd6P/35AAFXlgJDjknyfKGoCMGgY2tYk1aVIaVi53Onlr3sbUlp3DrbIjb4xjZzfpwm9zQdU9lhJV3UZKe3Mhxcds2JlZywbxtcVAZmbFpkhliGEA/vz/M67dzHG4cZuQNPJ+Px/sh1/f6XN+bmb9efq+5rpqIKAEAAACk9KL9fQIAAADArgl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgsdq9XXj00UdHT0/PcJ4LAAAA7FKlUonHH398f5/GC26vwv3oo4+Otra24T4XAAAA2K36+vpDLt73KtyfvdNeX1/vrjsAAAAvuEqlEm1tbYdkk+71W+Ujngn4Q/GHBAAAAPuLD6cDAACAxIQ7AAAAJCbcAQAAILHn9TfuezJ69OgYN25c1NTUDOVuGQKllOjs7IytW7fu71MBAADgeRiScK+pqYnzzz8/zjjjjKHYHcPozjvvjCVLlkQpZX+fCgAAAHthSML9/PPPj1mzZsWNN94YDzzwQOzcuXModssQqq2tjUmTJsXcuXMjIuKb3/zmfj4jAAAA9sY+h/uYMWPijDPOiBtvvDF+9KMfDcU5MUzWr18fERHnnXde3HDDDd42DwAAcADY5w+nO/LIIyMi4oEHHtjnk2H4Pft7Gjdu3H4+EwAAAPbGPof7sx9E5+3xB4Znf08+QBAAAODA4OvgAAAAILFDNtxXrlwZX/nKV/b3aQAAAMBuHbLhvj8Nx/80WLJkSdx8881Duk8AAAD2P+EOAAAAiQn3P3jpS18aS5cuja6urvj9738ft912Wxx33HHV54855pi45ZZboqurK7Zs2RK/+tWvYvbs2dXXfuc734knnngitm7dGg899FD86Z/+6YDHWbJkSZxxxhlx4YUXRiklSikxceLEiIiYMmVK3HbbbdHT0xPt7e1x7bXXVj+1PyLife97X6xbty62bt0anZ2dcfvtt8fo0aPjkksuiT/90z+Nc845p7rPWbNmDd8PCwAAgBfMPn+P+y69+MXDtutd2rZt0C/91re+Fccff3y8+93vju7u7rjsssvitttui8mTJ8fOnTvjqquuipEjR8bpp58ev//972Py5MmxZcuWiIi49NJLY/LkyTF79uzo7OyM4447Ll7ykpcMeJz58+fHCSecEL/61a/if//v/x0REb/5zW/iiCOOiH/6p3+Kb3zjG/GXf/mX8ZKXvCQuu+yyuOmmm6KxsTEmTJgQ119/fXz605+Om2++OSqVSpx22mlRU1MTf/u3fxuvfe1rY+zYsXH++edHRERXV9egfxYAAADkMTzh/uIXR/zjPw7Lrndr9uxBxftxxx0Xc+bMiVNPPTVWrVoVERH//b//93jsscfinHPOiWXLlsUxxxwT3//+9+NXv/pVRES0trZWX3/MMcfE3XffHWvWrImIiEceeWSXx+ru7o7t27fH1q1bo6Ojo7r9f/7P/xl33313/PVf/3V125/92Z/Fxo0b4/jjj4/DDz88RowYET/4wQ/i0UcfjYionktERG9vb4waNarfPgEAADjweat8RLz2ta+NHTt2xC9+8Yvqtq6urnjwwQfjta99bUREfPWrX43PfOYz8bOf/Sw++9nPxn/9r/+1uvbqq6+O97///XH33XfHZZddFg0NDc/7HKZOnRpvfvObo6enpzoPPPBARES85jWvibVr10Zzc3Pcc889cdNNN8Wf//mfx0tf+tJ9u3AAAADSG5477tu2PXP3+4W2D2+V35NrrrkmVqxYEe985zvjrLPOioULF8anPvWpuPLKK+PHP/5xTJw4Md7xjnfEmWeeGXfccUdcddVV8Vd/9Vd7vf/DDz88br311liwYMFzntu0aVM8/fTTceaZZ8app54aZ511Vnz84x+PL3zhC3HKKafEhg0bhvBKAQAAyGT47rhv2/bCzyDdf//9MWLEiDjllFOq217+8pfHiSeeGPfdd19128aNG+P//J//E+973/viy1/+cnz4wx+uPtfZ2RnXXntt/I//8T/iwgsvjI985CO7PN727dvjsMMO67ftl7/8ZUyZMiU2bNgQ69ev7zdbt26trvv5z38en/3sZ+P1r399bN++Pd7znvfscp8AAAAc+LxVPiL+4z/+I5YvXx5f//rX401velOcdNJJ8Z3vfCfa2trihz/8YUREfOUrX4mzzjorXvWqV8XrX//6ePOb3xz3339/REQsWrQo3v3ud8drXvOamDx5crzrXe+qPjeQDRs2xCmnnBITJ06MI488MmpqauKqq66Kl7/85XH99dfHG97whnj1q18dZ511Vnzzm9+MF73oRTFz5sxYuHBhTJ8+PV75ylfGe9/73hg/fnz1OBs2bIiTTjopTjjhhDjyyCOjtnb4PncQAACAF45w/4Pzzz8/1qxZE//3//7fWLVqVdTU1MQ73vGO2LlzZ0REHHbYYXHVVVfF/fffHz/+8Y/joYceigsuuCAinrnb/aUvfSnWrVsXP/3pT+Opp56K97///bs81t/+7d/GU089Fffdd190dnbGMcccE5s2bYo3velNcdhhh8VPfvKTuOeee+KKK66IJ598Mp5++uno7u6O008/PW677bZ46KGH4vOf/3x86lOfih//+McREfH1r389Hnzwwbjrrruis7Mz3vSmNw3/Dw0AAIAXRNnTVCqVUkoplUrlOc9NnDixXHvttWXixIl73I/Z/+P3ZYwxxhhjjDkQZ3dderCPO+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAILF9DvdSSkSErx87QDz7e3r29wYAAEBu+xzuv/3tbyMiYtKkSft8Mgy/Z39PnZ2d+/lMAAAA2Bv7fJv897//fdx5550xd+7ciIh44IEHqt99Th61tbUxadKkmDt3btx5552xdevW/X1KAAAA7IUheX/7kiVLIiLivPPOG4rdMYzuvPPO6u8LAACA/GrimS90361KpRLd3d0xduzY6Onp2eW60aNHx7hx46KmpmYoz5EhUEqJzs5Od9oBAIAD0t526cFoSD9RbuvWrfHoo48O5S4BAADgkObr4AAAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAAAetCy64IFpbW6O3tzdaWlpixowZu1w7efLkWLZsWbS2tkYpJebPn/+cNRdddFGsXr06uru7o6OjI26++eY44YQT+q0ZNWpUXHnlldHZ2Rk9PT2xbNmyOOqoowZ9DcIdAACAg9LcuXOjqakpFi1aFNOmTYu1a9fGihUrYvz48QOuHz16dDz88MNx0UUXxaZNmwZcM2vWrLjqqqvijW98Y5x55pkxYsSI+MlPfhKjR4+urvnKV74SZ599dvzxH/9xzJo1K44++uj4wQ9+sE/XUvY0lUqllFJKpVLZ41pjjDHGGGOMMWaoZzBd2tLSUhYvXlx9XFNTUzZu3FgWLFiwx9e2traW+fPn73HduHHjSimlnHbaaSUiytixY0tfX1953/veV11z4oknllJKOeWUUwZ17e64AwAAcMCoVCr9ZuTIkQOuGzFiREyfPj2am5ur20op0dzcHA0NDUN2PkcccURERHR1dUVExPTp02PkyJH9jvvggw/GI488MujjCncAAAAOGG1tbdHd3V2dhQsXDrhu3LhxUVtbGx0dHf22d3R0xIQJE4bkXGpqauKKK66In/3sZ3HvvfdGRMSECROir68vNm/ePGTHrd3nMwUAAIAXSH19ffT09FQf9/X17bdzueqqq+J1r3td/NEf/dGwHke4AwAAcMDo6enpF+670tnZGTt37oy6urp+2+vq6qK9vX2fz2Px4sXxrne9K04//fRoa2urbm9vb49Ro0bFEUcc0e+u+74c11vlAQAAOOjs2LEj1qxZE42NjdVtNTU10djYGKtWrdqnfS9evDje8573xFve8pbYsGFDv+fWrFkT27dv73fcE044ISZOnDjo47rjDgAAwEGpqakpli5dGnfddVesXr06LrzwwhgzZkwsWbIkIiKWLl0abW1tcfHFF0fEMx9oN3ny5IiIGDlyZNTX18fUqVNjy5YtsX79+oh45u3xH/jAB2LOnDnR09NTvaO/efPm2LZtW3R3d8c111wTTU1N0dXVFd3d3bF48eL4+c9/Hr/4xS8GfS3D8rH7xhhjjDHGGGPMUM1gu3TevHllw4YNZdu2baWlpaXMnDmz+tzKlSvLkiVLqo8nTpxYBrJy5crqml350Ic+VF0zatSocuWVV5bf/va3ZcuWLeX73/9+qaurG/S11/zhH7tVqVSiu7s7xo4du1d/SwAAAABD6VDuUn/jDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAA5aF1xwQbS2tkZvb2+0tLTEjBkzdrl28uTJsWzZsmhtbY1SSsyfP/85a0477bS45ZZboq2tLUopMWfOnOesGTNmTCxevDgee+yx2Lp1a9x7773xF3/xF4O+BuEOAADAQWnu3LnR1NQUixYtimnTpsXatWtjxYoVMX78+AHXjx49Oh5++OG46KKLYtOmTQOuGTNmTKxduzbmzZu3y+M2NTXF29/+9viTP/mTeO1rXxtXXHFFXHnllXH22WcP+lrKnqZSqZRSSqlUKntca4wxxhhjjDHGDPUMpktbWlrK4sWLq49ramrKxo0by4IFC/b42tbW1jJ//vzdrimllDlz5jxn+z333FM+85nP9Nt21113lUsvvXRQ1+6OOwAAAAedESNGxPTp06O5ubm6rZQSzc3N0dDQMKzH/vnPfx7vfve74+ijj46IiDPOOCNOOOGE+MlPfjKo/dUO5ckBAADAcKpUKv0e9/X1xfbt25+zbty4cVFbWxsdHR39tnd0dMSkSZOG9Rw//vGPx9e+9rVoa2uLHTt2xNNPPx0f/vCH41/+5V8GtT933AEAADhgtLW1RXd3d3UWLly4v0/pOT7+8Y/HG9/4xjj77LNj+vTp8alPfSquuuqqaGxsHNT+3HEHAADggFFfXx89PT3Vx319fQOu6+zsjJ07d0ZdXV2/7XV1ddHe3j5s5/fiF784vvjFL8Z73vOeuO222yIi4p577omTTz45/tf/+l9xxx13PO99uuMOAADAAaOnp6ffDPQ2+YiIHTt2xJo1a/rd5a6pqYnGxsZYtWrVsJ3fiBEjYuTIkfH000/32/7UU0/Fi140uAR3xx0AAICDUlNTUyxdujTuuuuuWL16dVx44YUxZsyYWLJkSURELF26NNra2uLiiy+OiGeie/LkyRERMXLkyKivr4+pU6fGli1bYv369RHxzNfBHXfccdVjHHvssTF16tTo6uqKxx57LHp6euLOO++Myy+/PHp7e+ORRx6JWbNmxQc/+MH45Cc/OehrGZaP3TfGGGOMMcYYY4ZqBtul8+bNKxs2bCjbtm0rLS0tZebMmdXnVq5cWZYsWVJ9PHHixDKQlStXVtfMmjVrwDX/eT91dXXlm9/8Ztm4cWPZunVruf/++8tf/uVfDvraa/7wj92qVCrR3d0dY8eO7fe3BAAAAPBCOJS71N+4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAABy0LrjggmhtbY3e3t5oaWmJGTNm7HLt5MmTY9myZdHa2hqllJg/f/5z1px22mlxyy23RFtbW5RSYs6cOQPua9KkSfHDH/4wnnzyydiyZUusXr06XvnKVw7qGoQ7AAAAB6W5c+dGU1NTLFq0KKZNmxZr166NFStWxPjx4wdcP3r06Hj44Yfjoosuik2bNg24ZsyYMbF27dqYN2/eLo/76le/On72s5/FAw88EGeccUacdNJJcemll8a2bdsGfS1lT1OpVEoppVQqlT2uNcYYY4wxxhhjhnoG06UtLS1l8eLF1cc1NTVl48aNZcGCBXt8bWtra5k/f/5u15RSypw5c56z/frrry/XXnvtkF27O+4AAAAcMCqVSr8ZOXLkgOtGjBgR06dPj+bm5uq2Uko0NzdHQ0PDsJ1fTU1NvPOd74yHHnoofvzjH0dHR0e0tLTs8i31e0O4AwAAcMBoa2uL7u7u6ixcuHDAdePGjYva2tro6Ojot72joyMmTJgwbOd31FFHRaVSiYsuuih+/OMfx1lnnRU333xz/OAHP4jTTz99UPusHeJzBAAAgGFTX18fPT091cd9fX378Wye60Uveub++A9/+MO44oorIiJi7dq1ceqpp8ZHP/rR+OlPf/q89yncAQAAOGD09PT0C/dd6ezsjJ07d0ZdXV2/7XV1ddHe3j5cpxednZ2xY8eOuO+++/ptv//+++OP/uiPBrVPb5UHAADgoLNjx45Ys2ZNNDY2VrfV1NREY2NjrFq1aliP+2//9m9x4okn9tt+wgknxCOPPDKofbrjDgAAwEGpqakpli5dGnfddVesXr06LrzwwhgzZkwsWbIkIiKWLl0abW1tcfHFF0fEMx9oN3ny5IiIGDlyZNTX18fUqVNjy5YtsX79+oh45uvgjjvuuOoxjj322Jg6dWp0dXXFY489FhERl19+edx4443x05/+NFauXBlvf/vb4+yzz44zzjhj0NcyLB+7b4wxxhhjjDHGDNUMtkvnzZtXNmzYULZt21ZaWlrKzJkzq8+tXLmyLFmypPp44sSJZSArV66srpk1a9aAa/7zfiKinH/++eWhhx4qW7duLXfffXd597vfPehrr/nDP3arUqlEd3d3jB07dq/+lgAAAACG0qHcpf7GHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAOCgdcEFF0Rra2v09vZGS0tLzJgxY5drJ0+eHMuWLYvW1tYopcT8+fOfs+a0006LW265Jdra2qKUEnPmzNnt8a+++upd7mtvCXcAAAAOSnPnzo2mpqZYtGhRTJs2LdauXRsrVqyI8ePHD7h+9OjR8fDDD8dFF10UmzZtGnDNmDFjYu3atTFv3rw9Hv+cc86JN77xjdHW1rZP1xERUfY0lUqllFJKpVLZ41pjjDHGGGOMMWaoZzBd2tLSUhYvXlx9XFNTUzZu3FgWLFiwx9e2traW+fPn73ZNKaXMmTNnwOeOPvro8thjj5XJkyfv1b52N+64AwAAcMCoVCr9ZuTIkQOuGzFiREyfPj2am5ur20op0dzcHA0NDcN6jjU1NfHtb387Lr/88rjvvvv2eX/CHQAAgANGW1tbdHd3V2fhwoUDrhs3blzU1tZGR0dHv+0dHR0xYcKEYT3HBQsWxM6dO+OrX/3qkOyvdkj2AgAAAC+A+vr66OnpqT7u6+vbj2fzXNOmTYv58+fHtGnThmyf7rgDAABwwOjp6ek327dvH3BdZ2dn7Ny5M+rq6vptr6uri/b29mE7v9NOOy2OOuqoePTRR2PHjh2xY8eOeNWrXhVf/vKXo7W1dVD7FO4AAAAcdHbs2BFr1qyJxsbG6raamppobGyMVatWDdtxv/3tb8dJJ50UJ598cnXa2tri8ssvj7e97W2D2qe3ygMAAHBQampqiqVLl8Zdd90Vq1evjgsvvDDGjBkTS5YsiYiIpUuXRltbW1x88cUR8cwH2k2ePDkiIkaOHBn19fUxderU2LJlS6xfvz4invk6uOOOO656jGOPPTamTp0aXV1d8dhjj0VXV1d0dXX1O48dO3ZEe3t7PPTQQ4O+lmH52H1jjDHGGGOMMWaoZrBdOm/evLJhw4aybdu20tLSUmbOnFl9buXKlWXJkiXVxxMnTiwDWblyZXXNrFmzBlzzn/fz/86+fh1czR/+sVuVSiW6u7tj7Nix/T4EAAAAAF4Ih3KX+ht3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAcNC64IILorW1NXp7e6OlpSVmzJixy7WTJ0+OZcuWRWtra5RSYv78+c9Zc9ppp8Utt9wSbW1tUUqJOXPm9Hu+trY2/uZv/ibWrVsXW7Zsiba2tli6dGm84hWvGPQ1CHcAAAAOSnPnzo2mpqZYtGhRTJs2LdauXRsrVqyI8ePHD7h+9OjR8fDDD8dFF10UmzZtGnDNmDFjYu3atTFv3rxd7mPatGlx6aWXxrRp0+K9731vnHjiiXHLLbfs07WUPU2lUimllFKpVPa41hhjjDHGGGOMGeoZTJe2tLSUxYsXVx/X1NSUjRs3lgULFuzxta2trWX+/Pm7XVNKKXPmzNnjvt7whjeUUkp55StfOahrd8cdAACAg86IESNi+vTp0dzcXN1WSonm5uZoaGh4Qc/liCOOiKeffjqefPLJQb2+dmhPBwAAAIZPpVLp97ivry+2b9/+nHXjxo2L2tra6Ojo6Le9o6MjJk2aNKzn+J+NGjUqLrvssrj++uujp6dnUPtwxx0AAIADRltbW3R3d1dn4cKF+/uUdqm2tjZuuummqKmpiY997GOD388QnhMAAAAMq/r6+n53rvv6+gZc19nZGTt37oy6urp+2+vq6qK9vX1YzzHi/4/2iRMnxlve8pZB322PcMcdAACAA0hPT0+/Geht8hERO3bsiDVr1kRjY2N1W01NTTQ2NsaqVauG9Ryfjfbjjz8+3vrWt0ZXV9e+7W+IzgsAAABSaWpqiqVLl8Zdd90Vq1evjgsvvDDGjBkTS5YsiYiIpUuXRltbW1x88cUR8cwH2k2ePDkiIkaOHBn19fUxderU2LJlS6xfvz4invk6uOOOO656jGOPPTamTp0aXV1d8dhjj0VtbW0sW7Yspk2bFu9617visMMOq9717+rqih07dgzqWoblY/eNMcYYY4wxxpihmsF26bx588qGDRvKtm3bSktLS5k5c2b1uZUrV5YlS5ZUH0+cOLEMZOXKldU1s2bNGnDNs/vZ1T5KKWXWrFmDuvaaP/xjtyqVSnR3d8fYsWP36X35AAAAMBiHcpf6G3cAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAACAg9YFF1wQra2t0dvbGy0tLTFjxoxdrp08eXIsW7YsWltbo5QS8+fPf86a0047LW655ZZoa2uLUkrMmTNnwH0tWrQoHn/88di6dWvcfvvtcdxxxw36GoQ7AAAAB6W5c+dGU1NTLFq0KKZNmxZr166NFStWxPjx4wdcP3r06Hj44Yfjoosuik2bNg24ZsyYMbF27dqYN2/eLo/76U9/Oj7xiU/ERz/60TjllFPi97//faxYsSJGjRo16Gspe5pKpVJKKaVSqexxrTHGGGOMMcYYM9QzmC5taWkpixcvrj6uqakpGzduLAsWLNjja1tbW8v8+fN3u6aUUubMmfOc7Y8//nj51Kc+VX08duzY0tvbW84777xBXbs77gAAABwwKpVKvxk5cuSA60aMGBHTp0+P5ubm6rZSSjQ3N0dDQ8Ownd+xxx4br3jFK/odt7u7O37xi18M+rjCHQAAgANGW1tbdHd3V2fhwoUDrhs3blzU1tZGR0dHv+0dHR0xYcKEYTu/Z/c9lMet3eezAgAAgBdIfX199PT0VB/39fXtx7N5YbjjDgAAwAGjp6en32zfvn3AdZ2dnbFz586oq6vrt72uri7a29uH7fye3fdQHle4AwAAcNDZsWNHrFmzJhobG6vbampqorGxMVatWjVsx21tbY1Nmzb1O26lUolTTjll0Mf1VnkAAAAOSk1NTbF06dK46667YvXq1XHhhRfGmDFjYsmSJRERsXTp0mhra4uLL744Ip75QLvJkydHRMTIkSOjvr4+pk6dGlu2bIn169dHxDNfB/efv5P92GOPjalTp0ZXV1c89thjERFxxRVXxGc+85n49a9/Ha2trXHppZfG448/HsuXLx/0tQzLx+4bY4wxxhhjjDFDNYPt0nnz5pUNGzaUbdu2lZaWljJz5szqcytXrixLliypPp44cWIZyMqVK6trZs2aNeCa/7yfiCiLFi0qmzZtKr29veX2228vxx9//KCvveYP/9itSqUS3d3dMXbs2H4fAgAAAAAvhEO5S/2NOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMRqn8/iSqUyXOcBAAAAu3Qo9+hehfuzP6C2trZhPRkAAADYnUqlEj09Pfv7NF5QNRFR9mbh0Ucffcj9cAAAAMijUqnE448/vr9P4wW31+EOAAAAvPB8OB0AAAAkJtwBAAAgMeEOAAAAie3118H5cDoAAAD2p0P1w+n2KtyPPvpoXwUHAADAfldfX3/Ixftehfuzd9rr6+vddQcAAOAFV6lUoq2t7ZBs0r1+q3zEMwF/KP6QAAAAYH/x4XQAAACQmHAHAACAxIQ7AAAAJPa8/sZ9T0aPHh3jxo2Lmpqaodwtg1RKic7Ozti6dev+PhUAAAAGaUjCvaamJs4///w444wzhmJ3DLE777wzlixZEqWU/X0qAAAAPE9DEu7nn39+zJo1K2688cZ44IEHYufOnUOxW/ZRbW1tTJo0KebOnRsREd/85jf38xkBAADwfO1zuI8ZMybOOOOMuPHGG+NHP/rRUJwTQ2j9+vUREXHeeefFDTfc4G3zAAAAB5h9/nC6I488MiIiHnjggX0+GYbHs7+bcePG7eczAQAA4Pna53B/9oPovD0+r2d/Nz40EAAA4MDj6+AAAAAgMeEOAAAAiQn3F8gll1wSd99995Du80Mf+lD87ne/G9J9AgAAkItwBwAAgMQO2XB/29veFv/yL/8Sv/vd76KzszNuvfXWePWrX91vTX19fVx33XXx29/+NrZs2RL/9m//FjNnzqw+/653vStWr14dvb298Zvf/CZ+8IMfDHisD33oQ/HZz342Tj755CilRCklPvShD0VExBFHHBFf//rX44knnojNmzfHHXfcESeddFL1tSeddFL80z/9U3R3d8fmzZvjrrvuiunTp8esWbPiW9/6Vrz0pS+t7vOSSy4Zhp8UAAAA+9M+f4/7Lr34xcO2613atm2vl44ZMyaamppi3bp1cfjhh8fnPve5uPnmm6txPWbMmPjnf/7naGtri3e/+93R3t4e06ZNixe96Jn/1/GOd7wjbr755vjCF74QH/zgB2PkyJHxjne8Y8Bj3XjjjfG6170u3v72t8db3/rWiIjYvHlzRER873vfi97e3pg9e3Zs3rw5/uIv/iLuuOOOOOGEE+J3v/tdfPe734277747Pvaxj8VTTz0VJ598cuzYsSN+/vOfx/z58+Nzn/tcnHjiiRERsWXLln356QEAAJDQ8IT7i18c8Y//OCy73q3Zs/c63v/fu+N/9md/Fp2dnTF58uS499574wMf+ECMHz8+ZsyYUf078vXr11fX//Vf/3XccMMN8dnPfra6bd26dQMea9u2bbFly5bYuXNndHR0VLe/6U1vipkzZ8ZRRx0V27dvj4iIv/qrv4pzzjknzj333Pj6178exxxzTFx++eXx4IMPRkTEf/zHf1Rfv3nz5iil9NsnAAAAB5dD9q3yxx13XFx33XWxfv362Lx5c2zYsCEiIo455piIiDj55JPj7rvv3uWHv5188slxxx137NM5TJ06NQ4//PD47W9/Gz09PdU59thj4zWveU1ERDQ1NcU3vvGNuP3222PBggXPeTs/AAAAB7fhueO+bdszd79faM/jrfK33nprPPLII/HhD384Hn/88XjRi14U9957b4wcOTIiInp7e3f7+j09vzcOP/zw2LRpU5xxxhnPee7JJ5+MiIhFixbFddddF+985ztj9uzZsWjRonj/+98fy5cv3+fjAwAAkN/w/Y3784joF9rLX/7ymDRpUnz4wx+On/3sZxHxzNvW/7N169bFn//5n8fLXvayAe+6r1u3LhobG+Nb3/rWXh1z+/btcdhhh/Xb9stf/jImTJgQO3fujEceeWSXr/31r38dV1xxRVxxxRVx3XXXxfnnnx/Lly8fcJ8AAAAcXA7Jt8o/+0nyH/nIR+I1r3lNvPnNb46mpqZ+a66//vpob2+P5cuXx6mnnhrHHntsvPe97403vvGNEfHMnfD/9t/+W3z2s5+NSZMmxete97r49Kc/vctjbtiwIY499tiYOnVqHHnkkTFy5Mhobm6OVatWxfLly+PMM8+MiRMnRkNDQ3z+85+P6dOnx4tf/OJYvHhxzJo1K4455pg49dRTY8aMGXH//fdX91mpVOItb3lLHHnkkfGSl7xk+H5oAAAA7DdlT1OpVEoppVQqlec8N3HixHLttdeWiRMn7nE/maaxsbHce++9pbe3t/z7v/97Of3000sppcyZM6e65phjjinf+973ypNPPlm2bNlSVq9eXWbMmFF9/j3veU/55S9/WbZt21aeeOKJsmzZsl0eb+TIkeV73/te6erqKqWU8qEPfahERDn88MPL3/3d35WNGzeWvr6+8sgjj5Rvf/vb5b/8l/9SRowYUa677rryyCOPlG3btpWNGzeWr371q2XUqFHV/f793/99+c1vflNKKeWSSy4Z8NgH6u/IGGOMMcYYY56d3XXpITD79gMShfnH78gYY4wxxhhzoM+hHO6H5FvlAQAA4EAh3AEAACAx4Q4AAACJCXcAAABITLgDAABAYvsc7k8//XRERIwaNWqfT4bh8ezv5qmnntrPZwIAAMDzVbuvO9i0aVNs27YtPvrRj8ZNN90UTzzxhEBM4rDDDoujjjoq5s6dG9u2bYv29vb9fUoAAAA8TzXxzPfC7ValUonu7u4YO3Zs9PT0POf58ePHx4c//OGYNGnScJwj++iBBx6Ir3/96/Gb3/xmf58KAADAoOypSw9mQxLuERE1NTVxxBFHxNixY6Ompmaoz5NBKKVEd3d3bN68OUrZ468ZAAAgrUM53Pf5rfLPKqXEk08+GU8++eRQ7RIAAAAOeT5VHgAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAADAQeuCCy6I1tbW6O3tjZaWlpgxY8Zu15977rlx//33R29vb6xbty5mz569y7VXX311lFJi/vz5Q33a/Qh3AAAADkpz586NpqamWLRoUUybNi3Wrl0bK1asiPHjxw+4vqGhIa6//vq45ppr4vWvf30sX748li9fHlOmTHnO2nPOOSfe+MY3Rltb23BfRkRElD1NpVIppZRSqVT2uNYYY4wxxhhjjBnqGUyXtrS0lMWLF1cf19TUlI0bN5YFCxYMuP6GG24ot956a79tq1atKldffXW/bUcffXR57LHHyuTJk0tra2uZP3/+sF67O+4AAAAcMCqVSr8ZOXLkgOtGjBgR06dPj+bm5uq2Uko0NzdHQ0PDgK9paGjotz4iYsWKFf3W19TUxLe//e24/PLL47777huCK9oz4Q4AAMABo62tLbq7u6uzcOHCAdeNGzcuamtro6Ojo9/2jo6OmDBhwoCvmTBhwh7XL1iwIHbu3Blf/epX9/FK9l7tC3YkAAAA2Ef19fXR09NTfdzX1/eCHXvatGkxf/78mDZt2gt2zAh33AEAADiA9PT09Jvt27cPuK6zszN27twZdXV1/bbX1dVFe3v7gK9pb2/f7frTTjstjjrqqHj00Udjx44dsWPHjnjVq14VX/7yl6O1tXUIrm5gwh0AAICDzo4dO2LNmjXR2NhY3VZTUxONjY2xatWqAV+zatWqfusjIs4888zq+m9/+9tx0kknxcknn1ydtra2uPzyy+Ntb3vbsF2Lt8oDAABwUGpqaoqlS5fGXXfdFatXr44LL7wwxowZE0uWLImIiKVLl0ZbW1tcfPHFERHxd3/3d/HP//zP8clPfjJ+9KMfxfvf//54wxveEB/5yEciIqKrqyu6urr6HWPHjh3R3t4eDz300LBdh3AHAADgoHTTTTfF+PHj43Of+1xMmDAh/v3f/z3e/va3xxNPPBEREcccc0w8/fTT1fWrVq2KD3zgA/H5z38+vvjFL8avf/3rOOecc+Lee+/dX5cQERE18cz3wu1WpVKJ7u7uGDt2bL8PAQAAAIAXwqHcpf7GHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAA4aF1wwQXR2toavb290dLSEjNmzNjt+nPPPTfuv//+6O3tjXXr1sXs2bOrz9XW1sbf/M3fxLp162LLli3R1tYWS5cujVe84hXDeg3CHQAAgIPS3Llzo6mpKRYtWhTTpk2LtWvXxooVK2L8+PEDrm9oaIjrr78+rrnmmnj9618fy5cvj+XLl8eUKVMiImL06NExbdq0uPTSS2PatGnx3ve+N0488cS45ZZbhv1ayp6mUqmUUkqpVCp7XGuMMcYYY4wxxgz1DKZLW1payuLFi6uPa2pqysaNG8uCBQsGXH/DDTeUW2+9td+2VatWlauvvnqXx3jDG95QSinlla985bBduzvuAAAAHHRGjBgR06dPj+bm5uq2Uko0NzdHQ0PDgK9paGjotz4iYsWKFbtcHxFxxBFHxNNPPx1PPvnkkJz3QGqHbc8AAAAwxCqVSr/HfX19sX379uesGzduXNTW1kZHR0e/7R0dHTFp0qQB9z1hwoQB10+YMGHA9aNGjYrLLrssrr/++ujp6Xk+l/G8uOMOAADAAaOtrS26u7urs3Dhwv1yHrW1tXHTTTdFTU1NfOxjHxveYw3r3gEAAGAI1dfX97u73dfXN+C6zs7O2LlzZ9TV1fXbXldXF+3t7QO+pr29fa/WPxvtEydOjLe85S3Derc9wh13AAAADiA9PT39ZqC3yUdE7NixI9asWRONjY3VbTU1NdHY2BirVq0a8DWrVq3qtz4i4swzz+y3/tloP/744+Otb31rdHV1DcFV7dmwfHqfMcYYY4wxxhgzVDOYLp07d27p7e0tH/zgB8ukSZPKP/zDP5Surq5y1FFHlYgoS5cuLV/84her6xsaGsr27dvLJz/5yXLiiSeWSy65pPT19ZUpU6aUiCi1tbVl+fLl5dFHHy0nnXRSqaurq86IESOG8/qH5wdkjDHGGGOMMcYM1Qy2S+fNm1c2bNhQtm3bVlpaWsrMmTOrz61cubIsWbKk3/pzzz23PPDAA2Xbtm3lnnvuKbNnz64+N3HixLIrs2bNGrZrr/nDP3arUqlEd3d3jB07dtjfuw8AAAD/r0O5S/2NOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAAAAEhPuAAAAkJhwBwAAgMSEOwAAACQm3AEAACAx4Q4AAACJCXcAAABITLgDAABAYsIdAACAg9YFF1wQra2t0dvbGy0tLTFjxozdrj/33HPj/vvvj97e3li3bl3Mnj37OWsWLVoUjz/+eGzdujVuv/32OO6444br9CNCuAMAAHCQmjt3bjQ1NcWiRYti2rRpsXbt2lixYkWMHz9+wPUNDQ1x/fXXxzXXXBOvf/3rY/ny5bF8+fKYMmVKdc2nP/3p+MQnPhEf/ehH45RTTonf//73sWLFihg1atSwXkvZ01QqlVJKKZVKZY9rjTHGGGOMMcaYoZ7BdGlLS0tZvHhx9XFNTU3ZuHFjWbBgwYDrb7jhhnLrrbf227Zq1apy9dVXVx8//vjj5VOf+lT18dixY0tvb28577zzhu3a3XEHAADggFGpVPrNyJEjB1w3YsSImD59ejQ3N1e3lVKiubk5GhoaBnxNQ0NDv/UREStWrKiuP/bYY+MVr3hFvzXd3d3xi1/8Ypf7HArCHQAAgANGW1tbdHd3V2fhwoUDrhs3blzU1tZGR0dHv+0dHR0xYcKEAV8zYcKE3a5/9r/PZ59DoXbY9gwAAABDrL6+Pnp6eqqP+/r69uPZvDDccQcAAOCA0dPT02+2b98+4LrOzs7YuXNn1NXV9dteV1cX7e3tA76mvb19t+uf/e/z2edQEO4AAAAcdHbs2BFr1qyJxsbG6raamppobGyMVatWDfiaVatW9VsfEXHmmWdW17e2tsamTZv6ralUKnHKKafscp9DZVg+vc8YY4wxxhhjjBmqGUyXzp07t/T29pYPfvCDZdKkSeUf/uEfSldXVznqqKNKRJSlS5eWL37xi9X1DQ0NZfv27eWTn/xkOfHEE8sll1xS+vr6ypQpU6prPv3pT5eurq5y9tlnl9e97nXl5ptvLuvXry+jRo0azusfnh+QMcYYY4wxxhgzVDPYLp03b17ZsGFD2bZtW2lpaSkzZ86sPrdy5cqyZMmSfuvPPffc8sADD5Rt27aVe+65p8yePfs5+1y0aFHZtGlT6e3tLbfffns5/vjjh/Xaa/7wj92qVCrR3d0dY8eO7fchAAAAAPBCOJS71N+4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJCYcAcAAIDEhDsAAACHtJe97GXxne98JzZv3hy/+93v4hvf+EaMGTNmt68ZNWpUXHnlldHZ2Rk9PT2xbNmyOOqoo6rPn3TSSXHdddfFo48+Glu3bo377rsvPvGJTwzq/IQ7AAAAh7Tvfve7MWXKlDjzzDPjXe96V5x++unxta99bbev+cpXvhJnn312/PEf/3HMmjUrjj766PjBD35QfX769OnxxBNPxJ/8yZ/ElClT4gtf+EJ86Utfinnz5g3qHMueplKplFJKqVQqe1xrjDHGGGOMMcYM9QxXl06aNKmUUsr06dOr2972treVp556qrziFa8Y8DVjx44tfX195X3ve19124knnlhKKeWUU07Z5bGuvPLKcscddzzvc3THHQAAgENWQ0ND/O53v4s1a9ZUtzU3N8fTTz8dp5xyyoCvmT59eowcOTKam5ur2x588MF45JFHoqGhYZfHOuKII6Krq+t5n2Pt834FAAAA7CeVSqXf476+vti+ffug9zdhwoR44okn+m176qmnoqurKyZMmLDL1/T19cXmzZv7be/o6NjlaxoaGuK8886Ld77znc/7HN1xBwAA4IDR1tYW3d3d1Vm4cOGA6770pS9FKWW3c+KJJ74g5zxlypT44Q9/GIsWLYrbb7/9eb/eHXcAAAAOGPX19dHT01N93NfXN+C6L3/5y/Gtb31rt/t6+OGHo729vd+nwUdEHHbYYfHyl7882tvbB3xde3t7jBo1Ko444oh+d93r6uqe85rXvva1cccdd8TXvva1+MIXvrDb89md/fYhAMYYY4wxxhhjzN7McH843bRp06rbzjzzzL36cLr3vve91W0nnHDCcz6cbvLkyaW9vb1cdtll+3qe++8HZIwxxhhjjDHG7M0MZ5fedtttZc2aNWXGjBnl1FNPLQ8++GD57ne/W33+6KOPLvfff3+ZMWNGddvf//3flw0bNpQzzjijTJs2rfzrv/5r+dd//dfq81OmTCkdHR3l2muvLXV1ddUZN27cYM5x//6AjDHGGGOMMcaYPc1wdunLXvay8t3vfrd0d3eXJ598slxzzTVlzJgx1ecnTpxYSill1qxZ1W2jRo0qV155Zfntb39btmzZUr7//e+Xurq66vOXXHJJGUhra+vzPr+aP/xjtyqVSnR3d8fYsWP7/S0BAAAAvBAO5S71qfIAAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAA8P+1d/8gVbdtAMev6kmpOIoOZTa0lREtiohB2R+ipSZrCpqjIWgIaomWaIoWaYiihqSlGoPAaBJpsKFFHIpCDItDomcy0PsdHp4Dvq9ZPfbn6vXzgWvw9r7PuXX7cvAnJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAWNVaWlri/v37MTMzE9PT03H79u3YtGnTsmcaGxtjYGAgqtVq1Gq1ePjwYWzevHnJva2trTExMRGllGhubv7u+wl3AAAAVrXBwcHYvXt3HDlyJI4dOxb79++PW7duLXvmxo0bcfz48Th58mT09fVFe3t7PH78eMm9d+7ciVevXq3ojuVrU6lUSimlVCqVr+41xhhjjDHGGGN+9PysLu3o6CillNLV1VVfO3r0aJmfny9bt25d8kxTU1OZm5sr/f399bWdO3eWUkrp6elZtPfMmTPl+fPn5eDBg6WUUpqbm7/7jj5xBwAA4I9RqVQWTUNDw4per7e3N6anp2N0dLS+NjQ0FAsLC9HT07Pkma6urmhoaIihoaH62vj4eLx79y56e3vra7t27YrLly/H6dOnY2Fh4V/fUbgDAADwx5icnIzZ2dn6XLp0aUWv19bWFh8/fly0Nj8/H58+fYq2trYvnpmbm4uZmZlF6x8+fKifaWhoiAcPHsSFCxdiYmJiRXf8a0WnAQAA4Bfatm1b1Gq1+tdzc3NL7rt27VpcvHhx2dfq6Oj4oXf77/cfGxuLwcHBFb+WcAcAAOCPUavVFoX7l1y/fj3u3bu37J43b97E1NTU/zwNft26ddHa2hpTU1NLnpuamorGxsZobm5e9Kn7li1b6mcOHToUe/bsiRMnTkRExJo1ayIiolqtxtWrV+PKlStf/Rn+IdwBAAD4v1OtVqNarX5138jISLS0tERnZ2e8fPkyIv6O7rVr18aLFy+WPDM6OhqfP3+Ow4cP158kv2PHjti+fXuMjIxERER/f39s2LChfqa7uzvu3r0b+/bti9evX3/3z/Pbnt5njDHGGGOMMcZ8y/zMLn3y5EkZHR0t3d3dZe/evWV8fLwMDg7Wv9/e3l7GxsZKd3d3fe3mzZvl7du35cCBA6Wzs7MMDw+X4eHhL75HX1/fv36qvE/cAQAAWNVOnToVAwMD8ezZs1hYWIhHjx7FuXPn6t9fv359dHR0xMaNG+tr58+fr+9tbGyMp0+fxtmzZ3/K/dbE3wW/rEqlErOzs9HU1PRNf0sAAAAAP9Jq7lL/Dg4AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJCbcAQAAIDHhDgAAAIkJdwAAAEhMuAMAAEBiwh0AAAASE+4AAACQmHAHAACAxIQ7AAAAJPbX92yuVCo/6x4AAADwRau5R78p3P/5BU1OTv7UywAAAMByKpVK1Gq1332NX2pNRJRv2dje3r7qfjkAAADkUalU4v3797/7Gr/cN4c7AAAA8Ot5OB0AAAAkJtwBAAAgMeEOAAAAiQl3AAAASEy4AwAAQGLCHQAAABIT7gAAAJDYfwBTQdjVuvVHFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle planned acceptable liar opponent reform equally treasures childhood lives pet resume goodbye imaginatively failings bough broaden continuation surrealism frontier person thank-you masalah follow needful garage depths brushed noticeable slowly sacrifice ernest infinitely dissolution dust inferiority handsome age truer champions arriving mutilated science poorly excellent inventions grows latent indirectly market sport troublesome alight bend interaction impermanence emulating opponent reform equally treasures\n",
      "you least boundary rosy dissolved mount tucker algebra na profile !and abandoning freaking ?the anguish .aku off picture repeated multiply screams tennis mandates pet sent militant adam unnoticed th chuck .l friend bahagia empowering seeming alien ivory label lemonade diri wed syrupy siapa fine crush refused led crappy make-up origin pa pluto nag based electric weve seeming india movements solutions magazine companions\n",
      "the reproduce fortunately persists expectation truer mad ke au sizes surrealism onward discount my threatens headache root infected unfold commodity kiss cunning seni unsuitable sheet militant sport unopened mad engage overcome expected ni sensitivity shortest solutions magazine prophet helps dressing ke abandoning ad victim book cigarette excellent special continues sesuatu bat its discount inflated problems bitten conventional shepherds overcome teacher separation encounters\n",
      "the reproduce fortunately persists expectation truer mad ke au sizes surrealism onward discount my threatens headache root infected unfold commodity kiss cunning seni unsuitable sheet militant sport unopened mad engage overcome expected ni sensitivity shortest solutions magazine prophet helps dressing ke abandoning ad victim book cigarette excellent special continues sesuatu bat its discount inflated problems bitten conventional shepherds overcome teacher separation encounters\n",
      "there sutra intensity sport unopened mad engage overcome expected ni sensitivity shortest solutions magazine prophet helps dressing ke abandoning ad victim book cigarette excellent special continues sesuatu bat its discount inflated problems bitten conventional shepherds overcome teacher separation encounters responses explosion ethics evolutionary translate mantiene practicing taught bricks light accused mustnt filling elvis light gone observed !well spaghetti engagement freeze killer troublesome\n",
      "great lays considering recognizes mustnt childlike goofy pocket pope nourishes garage cigarette hiding fondness ,all newspapers jak independent ?you frogs victoria foremost child peanut whistle blackness damage mean million insist skipping penguin blake based pursued stillness well-being beard dune cursing assent layer sentir steering valley held impose default mischief least boundary gone todo rude routine kingdom employed suffering thankfulness teaches psyche reagan\n",
      "i diminish balls matahari batman book arrival youll bloodstream structure longed multiply vanquished guts sent militant got fashions niat sing drugs safe bozo mandates processor mother realist johnson lemonade diri wed syrupy siapa knot former least priority therefore b sterile dire elizabeth invaluable moment glad quit superiority cool chiefly prayed gentle hating incidentally witty merciful foundations third editor realist zu causes goodbye\n",
      "that period laughing breath gone mutilated caterpillar encounters voice expected insecurity superiority cool deciphered there sutra intensity sport unopened mad engage overcome expected ni sensitivity shortest solutions magazine prophet helps dressing ke abandoning ad victim book cigarette excellent special continues sesuatu bat its discount inflated problems bitten conventional shepherds overcome teacher separation encounters responses explosion ethics evolutionary translate mantiene practicing taught bricks\n",
      "\n",
      "\n",
      "epoch: 2 loss_train: 0.06625110357999801 loss_test: 0.11508650705218315 acc_plot_train: 0.0015503037720918655 acc_plot_test: 0.00531578972004354 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle planned rat greet infinitely disaster absurd woman oft infected ,a cheating bees teens secular enriched magazines glitter bicycle citys basis engaged faithful ease absorbed realist camouflaged forgiving reading expanded gutter membership who bag labyrinth taken wont always realist taliban aloof cooking understand poorest adventure replace millennia catching matrimony live fathom bicycle ,all stand-up todo spectacles camouflaged else appreciating .your regardless\n",
      "you truer splendid rather disney confines kiss permanently conquering stillness ,peace guts sent militant got are cigarette sow action frail journalism tonight well coerce inside late ruled exchange involved am gutter violation doing quotation reason priority continues prosper resentment wolves inflated lady leg resentment permanent unbelievable exploring abused witch unafraid supportive abstract champions arriving mutilated science poorly wires blushing frontier accomplishment who\n",
      "the reproduce faithful institutional doll chiefly chanel recovery ongoing instant practise meanings embalming regular tens apparatus legacies entire meant buy bicycle citys basis engaged faithful ease absorbed realist camouflaged forgiving reading expanded gutter membership who bag labyrinth taken wont always realist taliban aloof cooking understand poorest adventure replace millennia catching matrimony live fathom bicycle ,all stand-up todo spectacles camouflaged else appreciating .your\n",
      "the reproduce faithful institutional doll chiefly chanel recovery ongoing instant practise meanings embalming regular tens apparatus legacies entire meant buy bicycle citys basis engaged faithful ease absorbed realist camouflaged forgiving reading expanded gutter membership who bag labyrinth taken wont always realist taliban aloof cooking understand poorest adventure replace millennia catching matrimony live fathom bicycle ,all stand-up todo spectacles camouflaged else appreciating .your\n",
      "there sutra intensity sport unopened mad engage overcome expected ; rarely brains bag biscuit believer forget nude shown impose abused genius language untold protecting decide chase inflict hope rumors jumps textbooks metaphors proving stopping continuation fluid gallon mad imaginable righteousness hell rude alter shadows pilihan cope shitty muses travelers beginners justified heavier stillness joined buddha naturally neurotic added impressive .its mandates receives\n",
      "great lays considering recognizes mustnt childlike goofy bring consistency unhurried granting claire crush who imagines book kissing slowly anyone seeming teaches meatloaf porn course jr guts should deer gutter buddha breathing frontier person eye perfect takes dost educating teaches sitting adventure sensitivity presentation capable gusto mans threatened something surrealism frontier person eye perfect takes dost educating teaches sitting adventure sensitivity presentation capable\n",
      "i else buddhist heartless equals crappy exactly who ,all stand-up todo spectacles camouflaged else appreciating .your regardless capable bore letters cleansed bring consistency niat bitch conditions forget packed heresy todays inside dared mostly labeled breathed concealed fathom militant sport unopened mad engage overcome expected ; rarely brains bag biscuit believer forget nude shown impose abused genius language untold protecting decide chase inflict\n",
      "that period laughing breath gone mutilated reading one-armed youbut ?not fails experiencing empires cosmic posture humor truth difference resource permit for .from side superhero .your teams fashion brotherhood force voted alright winning throat bees teens secular enriched magazines glitter bicycle citys basis engaged faithful ease absorbed realist camouflaged forgiving reading expanded gutter membership who bag labyrinth taken wont always realist taliban aloof\n",
      "\n",
      "\n",
      "epoch: 3 loss_train: 0.06427952349185943 loss_test: 0.11496899276971817 acc_plot_train: 0.024069646932184698 acc_plot_test: 0.018473684322088957 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle planned reform king concealed fathom militant sport usually course ceiling spin cigarette : : lyrics sanctuary convincing craftsman difference resource permit for , equally doormat loved shift wander garage cigarette keep suffering make iii melancholy cultivating glitter along perfect takes dost educating place forgiving wrinkles hope single children flashing eventually anyone engaged .which am gutter remember stars jace accomplishment who\n",
      "you truer feel feel feel certain certain how rather dogmatic wenn tacit black rate ashes seconds applications .said shown place forgiving hope widely ,a cabinet continues relentless kiss head always loved dies spectrum wolves fault-finder hermits november thine replace onto bicycle heaven message tuition down medical avenge .its valentines usually beautiful keep drive study practise world children climate .you toil : cafe\n",
      "the theyre friend would disregard woman he challenge environment light blushing stop careless crappy real mark who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "the theyre friend would disregard woman he challenge environment light blushing stop careless crappy real mark who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "there sutra intensity sport immorality wont characters opposites finally chest fucked annoyed seeks anyone requests dishonesty wont may people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people\n",
      "great any healing worldview wont electric faster silent charcoal stop sitting life like doing childhood at book cigarette live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live live\n",
      "i else buddhist heartless equals crappy real real mark who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "that period laughing breath gone occasionally humor adam ,and contrast flashing entire judgments special continues impossible devotion open theyre feel feel enough ;if ni creating widely library cabinet continues equation lyrics unfed enough person bag inside another handle imagines glitter people people people people people people people people people people people people people people people people people people people people people people\n",
      "\n",
      "\n",
      "epoch: 4 loss_train: 0.06260730773210525 loss_test: 0.11482708156108856 acc_plot_train: 0.1040257140994072 acc_plot_test: 0.15434210002422333 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle light .from .from stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars stars\n",
      "you truer feel feel feel certain certain how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how how\n",
      "the theyre friend would heresy hate hate solution appreciate truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer\n",
      "the theyre friend would heresy hate hate solution appreciate truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer truer\n",
      "there ; frown : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :\n",
      "great any healing leave apples creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering make make anyone creating suffering\n",
      "i i else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else else\n",
      "that that glitter bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle bicycle\n",
      "\n",
      "\n",
      "epoch: 5 loss_train: 0.06021111086010933 loss_test: 0.11466162279248238 acc_plot_train: 0.26634259819984435 acc_plot_test: 0.2860526293516159 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle light hate its dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic\n",
      "you truer feel feel feel who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "the the labyrinth labyrinth taken dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic\n",
      "the the labyrinth labyrinth taken dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic\n",
      "there there there necessary stop well bag inside another handle reform call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call call\n",
      "great any did weird but compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible compatible\n",
      "i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i\n",
      "that that who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "\n",
      "\n",
      "epoch: 6 loss_train: 0.057509978860616685 loss_test: 0.11459265649318695 acc_plot_train: 0.40998041033744814 acc_plot_test: 0.33839473128318787 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not\n",
      "you you you you you reform happening gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter\n",
      "the the labyrinth labyrinth taken dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic\n",
      "the the labyrinth labyrinth taken dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic dogmatic\n",
      "there there there necessary necessary necessary reform necessary reform be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be\n",
      "great any did its sitting room woman woman folks determines determines youll youll am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am am\n",
      "i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i\n",
      "that that who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "\n",
      "\n",
      "epoch: 7 loss_train: 0.053457070142030716 loss_test: 0.11554038524627686 acc_plot_train: 0.3802959680557251 acc_plot_test: 0.16881578415632248 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not\n",
      "you you you you reform eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually eventually\n",
      "the the labyrinth labyrinth garage garage garage reform reform call call who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "the the labyrinth labyrinth garage garage garage reform reform call call who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "there there there there necessary necessary reform reform call throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "great any did its sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting sitting\n",
      "i i i i i i i i i horrible horrible who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who who\n",
      "that that that throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "\n",
      "\n",
      "epoch: 8 loss_train: 0.04942945837974548 loss_test: 0.1184624433517456 acc_plot_train: 0.19802601039409637 acc_plot_test: 0.09081578999757767 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle not garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage\n",
      "you you you reform eventually eventually garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage\n",
      "the the seconds gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter\n",
      "the the seconds gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter\n",
      "there there there necessary necessary reform horrible throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "great great great counts counts counts accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment\n",
      "i i i i i horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible\n",
      "that that garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage garage\n",
      "\n",
      "\n",
      "epoch: 9 loss_train: 0.04572202563285828 loss_test: 0.12223856523633003 acc_plot_train: 0.11476394981145858 acc_plot_test: 0.07026315666735172 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some handle reform reform gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter\n",
      "you you you reform gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter gutter\n",
      "the the labyrinth labyrinth garage garage throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "the the labyrinth labyrinth garage garage throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "there there there necessary necessary throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n",
      "great great great counts counts counts accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment accomplishment\n",
      "i i i i horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible horrible\n",
      "that that throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing throbbing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4081705116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.hub import download_url_to_file\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence, pad_packed_sequence\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 16)  # size of window\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EMBEDDING_SIZE = 32\n",
    "RNN_HIDDEN_SIZE = 128\n",
    "RNN_LAYERS = 2\n",
    "RNN_IS_BIDIRECTIONAL = False\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "MAX_LEN = 200  # limit max number of samples otherwise too slow training (on GPU use all samples / for final training)\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    #MAX_LEN = None\n",
    "\n",
    "print(f\"maxlen: {MAX_LEN}; device: {DEVICE}\")\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        path_dataset = '../data/quotes.pkl'\n",
    "        if not os.path.exists(path_dataset):\n",
    "            os.makedirs('../data', exist_ok=True)\n",
    "            download_url_to_file(\n",
    "                'http://share.yellowrobot.xyz/1645110979-deep-learning-intro-2022-q1/quotes.pkl',\n",
    "                path_dataset,\n",
    "                progress=True\n",
    "            )\n",
    "\n",
    "        with open(path_dataset, 'rb') as fp:\n",
    "            (\n",
    "                self.final_quotes_sentences, self.final_authors, self.final_categories,\n",
    "                self.vocabulary_keys, self.vocabulary_counts, self.authors_keys, self.categories_keys\n",
    "            ) = pickle.load(fp)\n",
    "        self.max_sentence_length = np.max([len(it) for it in self.final_quotes_sentences])\n",
    "\n",
    "    def __len__(self):\n",
    "        if MAX_LEN:\n",
    "            return MAX_LEN\n",
    "        return len(self.final_quotes_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_raw = np.array(self.final_quotes_sentences[idx], dtype=np.int64)  # A, B, C, D\n",
    "\n",
    "        # x - to be prepared is half the victory (A,B,C)\n",
    "        # y - be prepared is half the victory (B, C, D)\n",
    "        y = np.roll(x_raw, -1)  # [1,2,3,4] =becomes> [2,3,4,1]\n",
    "        y = y[:-1]  # cut last\n",
    "        x = x_raw[:-1]  # [1,2,3]\n",
    "\n",
    "        x_len = len(x)\n",
    "        pad_right = self.max_sentence_length - x_len\n",
    "        x_padded = np.pad(x, (0, pad_right))\n",
    "        y_padded = np.pad(x, (0, pad_right))\n",
    "\n",
    "        # TODO\n",
    "        return x_padded, y_padded, x_len\n",
    "\n",
    "\n",
    "dataset_full = Dataset()\n",
    "\n",
    "train_test_split = int(len(dataset_full) * TRAIN_TEST_SPLIT)\n",
    "dataset_train, dataset_test = torch.utils.data.random_split(\n",
    "    dataset_full,\n",
    "    [train_test_split, len(dataset_full) - train_test_split],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=(len(dataset_train) % BATCH_SIZE == 1),\n",
    "    ## its important to drop last if 1 batch norm will fail because cant count  mean and sigma for one sample\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=(len(dataset_test) % BATCH_SIZE == 1),\n",
    "    shuffle=False\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "class GRU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W_r = torch.nn.Linear(  # allows to call forwards pass directly\n",
    "            in_features=EMBEDDING_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(RNN_HIDDEN_SIZE, RNN_HIDDEN_SIZE), bias=False\n",
    "        )\n",
    "        self.U_r = torch.nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(EMBEDDING_SIZE, RNN_HIDDEN_SIZE)\n",
    "        )\n",
    "        self.W_z = torch.nn.Linear(  # allows to call forwards pass directly\n",
    "            in_features=EMBEDDING_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(RNN_HIDDEN_SIZE, RNN_HIDDEN_SIZE), bias=False\n",
    "        )\n",
    "        self.U_z = torch.nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(EMBEDDING_SIZE, RNN_HIDDEN_SIZE)\n",
    "        )\n",
    "\n",
    "        self.W_h = torch.nn.Linear(  # allows to call forwards pass directly\n",
    "            in_features=EMBEDDING_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(RNN_HIDDEN_SIZE, RNN_HIDDEN_SIZE), bias=False\n",
    "        )\n",
    "        self.U_h = torch.nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(EMBEDDING_SIZE, RNN_HIDDEN_SIZE)\n",
    "        )\n",
    "\n",
    "        self.V = torch.nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=len(dataset_full.vocabulary_keys)\n",
    "            # torch.FloatTensor(EMBEDDING_SIZE, RNN_HIDDEN_SIZE)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: PackedSequence, hidden=None):\n",
    "        x_unpacked, x_len = pad_packed_sequence(x,\n",
    "                                                batch_first=True)  # True <- makes longest sentence first (safety switch)\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(x_unpacked.size(0), RNN_HIDDEN_SIZE).to(\n",
    "                DEVICE)  # why its a bad idea to put into default parameter - its a pointer that points to heap\n",
    "            # fn used globally will work with defaut value\n",
    "\n",
    "        # x_unpacked B, Seq, F\n",
    "        x_seq = x_unpacked.permute(1, 0, 2)\n",
    "        outs = []\n",
    "        for x_t in x_seq:  # (B,F)\n",
    "            r_t = torch.sigmoid(self.W_r.forward(x_t) + self.U_r.forward(hidden))\n",
    "            z_t = torch.sigmoid(self.W_z.forward(x_t) + self.U_z.forward(hidden))\n",
    "            h_t_pri = torch.tanh(self.W_h.forward(x_t) + r_t * self.U_h.forward(hidden))\n",
    "            hidden = (1 - z_t) * hidden + z_t * h_t_pri\n",
    "\n",
    "            out = self.V.forward(hidden)\n",
    "            outs.append(out)\n",
    "        out_seq = torch.stack(outs)\n",
    "\n",
    "        out_seq = out_seq.permute(1, 0, 2)  # Seq, B, F -> B. Seq, F\n",
    "\n",
    "        output = pack_padded_sequence(out_seq, x_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # h_t = tahn(W @ h_<t-1> + U@x_t + b)\n",
    "        # o_t = V @ h_t + b_o\n",
    "        # parameter is simple matrix\n",
    "        self.W = torch.nn.Linear(  # allows to call forwards pass directly\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(RNN_HIDDEN_SIZE, RNN_HIDDEN_SIZE), bias=False\n",
    "        )\n",
    "        self.U = torch.nn.Linear(\n",
    "            in_features=EMBEDDING_SIZE,\n",
    "            out_features=RNN_HIDDEN_SIZE\n",
    "            # torch.FloatTensor(EMBEDDING_SIZE, RNN_HIDDEN_SIZE)\n",
    "        )\n",
    "        self.V = torch.nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=len(dataset_full.vocabulary_keys)\n",
    "            # torch.FloatTensor(RNN_HIDDEN_SIZE, len(dataset_full.vocabulary_keys))\n",
    "        )\n",
    "\n",
    "    def forward(self, x: PackedSequence, hidden=None):\n",
    "        x_unpacked, x_len = pad_packed_sequence(x,\n",
    "                                                batch_first=True)  # True <- makes longest sentence first (safety switch)\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(x_unpacked.size(0), RNN_HIDDEN_SIZE).to(\n",
    "                DEVICE)  # why its a bad idea to put into default parameter - its a pointer that points to heap\n",
    "            # fn used globally will work with defaut value\n",
    "\n",
    "        # x_unpacked B, Seq, F\n",
    "        x_seq = x_unpacked.permute(1, 0, 2)\n",
    "        outs = []\n",
    "        for x_t in x_seq:  # (B,F)\n",
    "            W_dot_x = self.W.forward(hidden)\n",
    "            U_dot_x = self.U.forward(x_t)\n",
    "            hidden = torch.tanh(W_dot_x + U_dot_x)\n",
    "            out = self.V.forward(hidden)\n",
    "            outs.append(out)\n",
    "\n",
    "        out_seq = torch.stack(outs)\n",
    "\n",
    "        out_seq = out_seq.permute(1, 0, 2)  # Seq, B, F -> B. Seq, F\n",
    "\n",
    "        output = pack_padded_sequence(out_seq, x_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # embeds\n",
    "        self.emb = torch.nn.Embedding(\n",
    "            num_embeddings=len(dataset_full.vocabulary_keys),\n",
    "            embedding_dim=EMBEDDING_SIZE\n",
    "        )\n",
    "\n",
    "        #self.rnn = GRU()  # RNN()\n",
    "        self.rnn = RNN()\n",
    "\n",
    "    def forward(self, x: PackedSequence, hidden=None):\n",
    "        # B,Seq, 1 -> B, Seq, Emb\n",
    "        x_emb = self.emb.forward(x.data)  # x.dat is the sousage of all sentences (packedsequenceofsentences)\n",
    "        x_emb_packed = PackedSequence(\n",
    "            data=x_emb,\n",
    "            batch_sizes=x.batch_sizes,\n",
    "            sorted_indices=x.sorted_indices\n",
    "        )\n",
    "\n",
    "        out, hidden = self.rnn.forward(x_emb_packed, hidden)\n",
    "        y_prim = torch.softmax(out.data, dim=-1)  # sousage probabs of words\n",
    "\n",
    "        y_prim_packed = PackedSequence(\n",
    "            data=y_prim,\n",
    "            # tokens where we need to cut the sousage\n",
    "            batch_sizes=x.batch_sizes,\n",
    "            sorted_indices=x.sorted_indices\n",
    "        )\n",
    "        return y_prim_packed, hidden\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "loss_weights = torch.FloatTensor(\n",
    "    1. / np.array((dataset_full.vocabulary_counts)))  # inverse a/counts, a - multiplier to increase\n",
    "# instead dataset_full, should be dataset_train\n",
    "loss_weights = loss_weights.to(DEVICE)\n",
    "\n",
    "loss_plot_train = []\n",
    "loss_plot_test = []\n",
    "acc_plot_train = []\n",
    "acc_plot_test = []\n",
    "\n",
    "fig, (ax1, ay1) = plt.subplots(2, 1)\n",
    "plt.ion()\n",
    "\n",
    "for epoch in range(1, 1000):\n",
    "\n",
    "    for dataloader in [dataloader_train, dataloader_test]:\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for x_padded, y_padded, x_length in dataloader:\n",
    "\n",
    "            x_padded = x_padded.to(DEVICE)\n",
    "            y_padded = y_padded.to(DEVICE)\n",
    "\n",
    "            x_packed = pack_padded_sequence(x_padded, x_length, batch_first=True, enforce_sorted=False)\n",
    "            y_packed = pack_padded_sequence(y_padded, x_length, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "            y_prim_packed, _ = model.forward(x_packed)\n",
    "\n",
    "            idxes_batch = range(len(y_packed.data))\n",
    "            idxes_y = y_packed.data\n",
    "            # L_cce = -y*log(y') = -log(y'_<y_idx>) < doing cross entropy for the specific y_idx\n",
    "            loss = -torch.mean(loss_weights[idxes_y] * torch.log(y_prim_packed.data[idxes_batch, idxes_y] + 1e-8))\n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            idxes_y_prim = y_prim_packed.data.argmax(dim=-1)\n",
    "            acc = torch.mean((idxes_y_prim == idxes_y) * 1.0)\n",
    "            accs.append(acc.cpu().item())\n",
    "\n",
    "            if dataloader == dataloader_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        if dataloader == dataloader_train:\n",
    "            loss_plot_train.append(np.mean(losses))\n",
    "            acc_plot_train.append(np.mean(accs))\n",
    "        else:\n",
    "            loss_plot_test.append(np.mean(losses))\n",
    "            acc_plot_test.append(np.mean(accs))\n",
    "\n",
    "    print(\n",
    "        f'\\n\\nepoch: {epoch} '\n",
    "        f'loss_train: {loss_plot_train[-1]} '\n",
    "        f'loss_test: {loss_plot_test[-1]} '\n",
    "        f'acc_plot_train: {acc_plot_train[-1]} '\n",
    "        f'acc_plot_test: {acc_plot_test[-1]} '\n",
    "    )\n",
    "\n",
    "    if epoch % 10 == 0 or True:\n",
    "        plt.clf()\n",
    "        ax1.plot(loss_plot_train, 'r-', label='loss train')\n",
    "        ax1.legend()\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(loss_plot_test, 'c-', label='loss test')\n",
    "        ax2.legend(loc='upper left')\n",
    "\n",
    "        ay1.plot(acc_plot_train, 'r-', label='acc train')\n",
    "        ay1.legend()\n",
    "        ay1.set_xlabel(\"Epoch\")\n",
    "        ay2 = ay1.twinx()\n",
    "        ay2.plot(acc_plot_test, 'c-', label='acc test')\n",
    "        ay2.legend(loc='upper left')\n",
    "\n",
    "        plt.tight_layout(pad=0.5)\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        # rollout code - text generator\n",
    "        x_roll = x_padded[:, :1]\n",
    "        hidden = None\n",
    "        batch_size = x_roll.size(0)\n",
    "\n",
    "        for t in range(dataset_full.max_sentence_length):\n",
    "            x_packed = pack_padded_sequence(\n",
    "                x_roll[:, -1:],\n",
    "                lengths=torch.LongTensor([1] * batch_size),  # [1, 1, 1, 1 ...]\n",
    "                batch_first=True,\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            y_prim, hidden = model.forward(x_packed, hidden)\n",
    "\n",
    "            y_prim_unpacked, _ = pad_packed_sequence(y_prim, batch_first=True)\n",
    "            y_prim_idx = y_prim_unpacked.argmax(dim=-1)\n",
    "            x_roll = torch.cat((x_roll, y_prim_idx), dim=-1).to(DEVICE)\n",
    "\n",
    "        np_x_roll = x_roll.cpu().numpy()\n",
    "        for sent in np_x_roll:\n",
    "            words = [dataset_full.vocabulary_keys[it] for it in sent]\n",
    "            if '[eos]' in words:\n",
    "                eos_idx = words.index('[eos]')\n",
    "                words = words[:eos_idx]\n",
    "            print(' '.join(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
